
# CHAPTER 12. 판별분석 및 기타 선형분류 모델

- 예측 변수의 특성에 따라 샘플을 그룹으로 군집화

    - 선형 판별 분석(LDA) : 수학적 방식 차용
    - k-최근접이웃법 : 알고리즘 방식 차용

## 1. 로지스틱 회귀

- 변수 간의 선형 관계, 잔차 제곱합을 최소화 하는 변수 선택 모델


- 인수의 우도 추정값을 최대화


- 로지스틱 회귀 모델에서 사건의 로그 오즈는 선형 함수 형태


- 다음과 같은 형태로 사건 확률 함수를 생성 (모델 항목에 대한 시그모이드 함수 : 확률 추정 값을 0과 1사이로 제한)

![logistic_Eq.PNG](attachment:logistic_Eq.PNG)

- 로지스틱 회귀 모델에서 비선형성에 대응하기위해 모델항목을 인수화

    - 제약 3차 스플라인 (Harrell, 2001)
    - 일반화가법모델 (Hastie and Tibshirani, 1990)

- 장점 : 단순하고 모델 항에대한 추정이 가능하다

## 2. 선형 판별 분석

- 데이터 분포를 학습해 결정 경계(Dicision Boundary)를 만들어 데이터를 분류 하는 모델


- 웰치 : 총 오분류 확률을 최소화 하는 접근 방법(클래스 확률과 변수의 다분량 분포를 사용)

![LDA_1.PNG](attachment:LDA_1.PNG)

- 단일 변수와 2개의 클래스를 갖는 경우 두 개의 클래스에 대해 예측 변수 값이 주어지면 클래스에 대한 확률에 따라 분류를 진행한다.

- 차원이 증가함에 따라 예측 변수의 분포가 다변량 정규분포를 따른다고 가정한다.

- 피셔 : 그룹 내 분산과 연관시켜 그룹 간 분산을 최대로하는 예측 변수의 선형 조합을 찾는다.

    - 두 범주의 평균이 서로 멀도록, 그 분산이 작도록 데이터를 사영(Projection)
    
![LDA_2.PNG](attachment:LDA_2.PNG)

- 데이터가 예측 변수보다 샘플의 수가 많고, 예측 변수는 독립적이다.

    - 예측 변수가 샘플보다 많거나 예측 변수 간의 연관성이 높은 경우 PCA를 실행해 차원 축소가 필요하다
    
    
- 각 변수가 샘플 분류에 얼마나 기여하는지 바로 이해할 수 있다.


- 데이터 전처리가 중요하다. (척도화, 중심화, 변수 선택)


- LDA는 예측 변수의 수보다 최소 샘플 수가 5~ 10배 많은 경우 적용하는 것을 추천


- 참고 : https://ratsgo.github.io/machine%20learning/2017/03/21/LDA/

## 3. 부분 최소 제곱 판별 분석 (PLS)


- 예측 변수 간의 높은 연관성, 예측 변수가 샘플 수 보다 많은 경우 문제점 有

    - 변수 제거, PCA 후 LDA 의 한계점 존재 (정보 손실)
    - 이 경우 판별 목적으로 PLS 사용을 추천
    

- PLS : 응답 변수와 최대 연광성을 갖는 잠재 변수를 찾는다


- 응답 변수와 연관된 차원 축소에 연관 기준을 사용 : 분류의 차원 축소에서 PCA 보다 PLS가 더 높은 성능

    - BUT, 차원 축소가 필요 없고 분류가 목적인 경우 LDA가 PLS보다 항상 낮은 오분류율을 보인다.
    
    
- 참고 : http://blog.daum.net/_blog/BlogTypeView.do?blogid=0QODh&articleno=32 

## 4. 벌점 모델

- 능형 회귀, 라소 회귀 처럼 벌점 항을 추가할 수 있음


- glmnet 모델을 사용


- 엘라스틱 넷과 마찬가지로 능형회귀와 라소 벌점을 동시에 사용하지만 구조가 다소 다르다.

![penalty.PNG](attachment:penalty.PNG)


- 벌점 기법은 LDA 모델에도 적용 가능 하다 : 유연 판별 분석 (Flexible discriminant analysis, FDA)

## 5. 최근접 축소 중심 모델 (Predictive Analysis for Microarrays, PAM)


- 고차원 문제에 최적화된 선형 분류 모델


- 각 클래스에 대한 훈련 데이터의 각 클래스 별 예측 변수의 평균값을 구해 데이터 중심값으로 사용

![PAM.PNG](attachment:PAM.PNG)

- 클래스 중심을 전체 중심에 가깝게 축소시키는 방법 : 꽃 받침 너비의 경우 virginica 중심이 전체 중심값에 도달하면 꽃받침 너비는 versicolor나 setosa인 꽃 분류에만 사용 -> 결과적으로 모델 훈련 과정에서 특징 선택이 동시에 수행된다.
